{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "本项目使用PaddleX进行目标检测，并生成端到端的模型。\n",
    "\n",
    "代码参考了[新人练习赛 钢铁缺陷检测挑战赛baseline改良方案](https://aistudio.baidu.com/aistudio/projectdetail/2360050)，并使用了其中的部分代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **1.构造数据集**\n",
    "\n",
    "将数据按照8:2的比例划分为训练集和测试集。这一部分直接使用了参考代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#首先将训练集解压缩\r\n",
    "!unzip -oq /home/aistudio/data/data105746/train.zip -d /home/aistudio/work/\r\n",
    "#测试集集解压缩\r\n",
    "!unzip -oq /home/aistudio/data/data105747/test.zip -d /home/aistudio/work/\r\n",
    "#删除生成的_MACOSX\r\n",
    "!rm -rf /home/aistudio/work/__MACOSX\r\n",
    "\r\n",
    "#遍历训练数据，将数据以8：2划分为训练集和验证集,如果已经完成了，就不需要在进行此步骤了\r\n",
    "\r\n",
    "import os\r\n",
    "name = [name for name in os.listdir('work/train/IMAGES') if name.endswith('.jpg')]\r\n",
    "\r\n",
    "train_name_list=[]\r\n",
    "for i in name:\r\n",
    "    tmp = os.path.splitext(i)\r\n",
    "    train_name_list.append(tmp[0])\r\n",
    "\r\n",
    "# 构造图片-xml的链接文件ori_train.txt\r\n",
    "with open(\"./work/train/ori_train.txt\",\"w\") as f:\r\n",
    "    for i in range(len(train_name_list)):\r\n",
    "        if i!=0: f.write('\\n')\r\n",
    "        line='IMAGES/'+train_name_list[i]+'.jpg'+\" \"+\"ANNOTATIONS/\"+train_name_list[i]+'.xml' \r\n",
    "        f.write(line)\r\n",
    "\r\n",
    "# 构造label.txt\r\n",
    "labels=['crazing','inclusion','pitted_surface','scratches','patches','rolled-in_scale']\r\n",
    "with open(\"./work/train/labels.txt\",\"w\") as f:\r\n",
    "    for i in range(len(labels)):\r\n",
    "        line=labels[i]+'\\n'\r\n",
    "        f.write(line)\r\n",
    "\r\n",
    "# 将ori_train.txt随机按照eval_percent分为验证集文件和训练集文件\r\n",
    "# eval_percent 验证集所占的百分比\r\n",
    "import random\r\n",
    "eval_percent=0.2;\r\n",
    "\r\n",
    "data=[]\r\n",
    "with open(\"work/train/ori_train.txt\", \"r\") as f:\r\n",
    "    for line in f.readlines():\r\n",
    "        line = line.strip('\\n')\r\n",
    "        data.append(line)\r\n",
    "\r\n",
    "index=list(range(len(data)))\r\n",
    "random.shuffle(index)\r\n",
    "\r\n",
    "# 构造验证集文件\r\n",
    "cut_point=int(eval_percent*len(data))\r\n",
    "with open(\"./work/train/val_list.txt\",\"w\") as f:\r\n",
    "    for i in range(cut_point):\r\n",
    "        if i!=0: f.write('\\n')\r\n",
    "        line=data[index[i]]\r\n",
    "        f.write(line)\r\n",
    "\r\n",
    "# 构造训练集文件\r\n",
    "with open(\"./work/train/train_list.txt\",\"w\") as f:\r\n",
    "    for i in range(cut_point,len(data)):\r\n",
    "        if i!=cut_point: f.write('\\n')\r\n",
    "        line=data[index[i]]\r\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **2、安装需要的PaddleX版本**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 安装paddlex\r\n",
    "# 需要注意paddlex1对于版本有所要求，所以最好更新对应的包版本\r\n",
    "!pip install \"numpy<=1.19.5\" -i https://mirror.baidu.com/pypi/simple\r\n",
    "! pip install paddlex==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#引入需要使用的库\r\n",
    "import matplotlib\r\n",
    "matplotlib.use('Agg') \r\n",
    "import os\r\n",
    "os.environ['GPU_VISIBLE_DEVICES'] = '0'#似乎不需要使用这条语句\r\n",
    "import paddlex as pdx\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **3、定义数据处理流程**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlex import transforms\r\n",
    "train_transforms = transforms.Compose([\r\n",
    "    #transforms.MixupImage(mixup_epoch=250),\r\n",
    "    #transforms.RandomDistort(),\r\n",
    "    #transforms.RandomExpand(),\r\n",
    "    #transforms.RandomCrop(),\r\n",
    "    transforms.RandomResizeByShort(short_sizes=[640, 672, 704, 736, 768, 800],\r\n",
    "                          max_size=1333,\r\n",
    "                          interp='RANDOM'), \r\n",
    "    transforms.RandomHorizontalFlip(), \r\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \r\n",
    "                         std=[0.229, 0.224, 0.225])\r\n",
    "])#在数据增强方面，大多数增强方式都不利于模型精度的提高，因此只选用了图片翻转，后期为了训练的稳定性，将关掉所有的数据增强。\r\n",
    "#另外进行了图片的缩放和归一化便于进行训练。\r\n",
    "\r\n",
    "eval_transforms = transforms.Compose([\r\n",
    "    transforms.ResizeByShort(short_size=800, \r\n",
    "                    max_size=1333,\r\n",
    "                    interp='CUBIC'), \r\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \r\n",
    "                std=[0.229, 0.224, 0.225])\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **4、定义数据集的Dataset**\n",
    "在训练前期仅使用训练集数据进行训练，在训练的末期将所有的图片都用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = pdx.datasets.VOCDetection(\r\n",
    "    data_dir='work/train',\r\n",
    "    file_list='work/train/train_list.txt',\r\n",
    "    label_list='work/train/labels.txt',\r\n",
    "    transforms=train_transforms,\r\n",
    "    shuffle=True)\r\n",
    "eval_dataset = pdx.datasets.VOCDetection(\r\n",
    "    data_dir='work/train',\r\n",
    "    file_list='work/train/val_list.txt',\r\n",
    "    label_list='work/train/labels.txt',\r\n",
    "    transforms=eval_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **5、定义模型网络**\n",
    "\n",
    "出于题目的排名是基于网络精度而进行的，所以选用精度更高的两阶段法Fast-RCNN，并且backbone选用ResNet101_vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = len(train_dataset.labels)\r\n",
    "model = pdx.det.FasterRCNN(num_classes=num_classes,\r\n",
    "                           backbone='ResNet101_vd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **6 、定义参数的学习率以及优化方式**\n",
    "\n",
    "\n",
    "因为使用了预训练模型所以在模型训练的初期使用warm-up学习率进行训练，在模型稳定了之后使用余弦退火衰减学习率。\n",
    "\n",
    "\n",
    "选择带有动量的SGD作为优化器，同时对所有的参数设置了L2正则化系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "train_batch_size = 2\r\n",
    "num_steps_each_epoch = 1120 // train_batch_size\r\n",
    "num_epochs = 80\r\n",
    "scheduler = paddle.optimizer.lr.CosineAnnealingDecay(\r\n",
    "    learning_rate=.0075, \r\n",
    "    T_max=num_steps_each_epoch * 12 // 3\r\n",
    "    )\r\n",
    "warmup_epoch = 1\r\n",
    "warmup_steps = warmup_epoch * num_steps_each_epoch\r\n",
    "scheduler = paddle.optimizer.lr.LinearWarmup(\r\n",
    "    learning_rate=scheduler,\r\n",
    "    warmup_steps=warmup_steps,\r\n",
    "    start_lr=0.00075,\r\n",
    "    end_lr=.0075)\r\n",
    "custom_optimizer = paddle.optimizer.Momentum(\r\n",
    "            scheduler,\r\n",
    "            momentum=.9,\r\n",
    "            weight_decay=paddle.regularizer.L2Decay(coeff=1e-04),\r\n",
    "            parameters=model.net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **7、开始训练模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.train(num_epochs = num_epochs, \r\n",
    "            train_dataset = train_dataset, \r\n",
    "            train_batch_size=train_batch_size, \r\n",
    "            eval_dataset=eval_dataset, \r\n",
    "            optimizer=custom_optimizer, \r\n",
    "            save_interval_epochs=1, \r\n",
    "            log_interval_steps=2, \r\n",
    "            save_dir='output/T001', \r\n",
    "            pretrain_weights='COCO', \r\n",
    "            metric=None, \r\n",
    "            early_stop=True, \r\n",
    "            early_stop_patience=5, \r\n",
    "            use_vdl=True#,\r\n",
    "            #pretrain_weights = None,\r\n",
    "            #resume_checkpoint = \"output/T008_101_vdMCpie3*lr/epoch_38_78.376\"\r\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **8、进行预测**\n",
    "\n",
    "对测试集中的照片进行预测,并生成可以直接提交的CSV文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddlex as pdx\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# 读取模型\r\n",
    "model = pdx.load_model('output/T001/best_model')\r\n",
    "#获取测试图片的序号\r\n",
    "name = [name for name in os.listdir('work/test/IMAGES') if name.endswith('.jpg')]\r\n",
    "\r\n",
    "test_name_list=[]\r\n",
    "for i in name:\r\n",
    "    tmp = os.path.splitext(i)\r\n",
    "    test_name_list.append(tmp[0])\r\n",
    "test_name_list.sort()\r\n",
    "# 建立一个标号和题目要求的id的映射\r\n",
    "num2index={'crazing':0,'inclusion':1,'pitted_surface':2,'scratches':3,'patches':4,'rolled-in_scale':5}\r\n",
    "\r\n",
    "result_list = []\r\n",
    "\r\n",
    "# 将置信度较好的框写入result_list\r\n",
    "for index in test_name_list:\r\n",
    "    image_name = 'work/test/IMAGES/'+index+'.jpg'\r\n",
    "    predicts = model.predict(image_name)\r\n",
    "    for predict in predicts:\r\n",
    "        if predict['score']<0.5: continue;\r\n",
    "        # 将bbox转化为题目中要求的格式\r\n",
    "        tmp=predict['bbox']\r\n",
    "        tmp[2]+=tmp[0]\r\n",
    "        tmp[3]+=tmp[1]\r\n",
    "        line=[index,tmp,num2index[predict['category']],predict['score']]\r\n",
    "        result_list.append(line)\r\n",
    "\r\n",
    "result_array = np.array(result_list)\r\n",
    "df = pd.DataFrame(result_array,columns=['image_id','bbox','category_id','confidence'])\r\n",
    "\r\n",
    "df.to_csv('output/T001/submission.csv',index=None)\r\n",
    "#直接夹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **9、预测结果可视化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in test_name_list:\r\n",
    "    image_name = 'work/test/IMAGES/'+index+'.jpg'\r\n",
    "    predicts = model.predict(image_name)\r\n",
    "    pdx.det.visualize(image_name, predicts, threshold=0.5, save_dir='output/T001/visualize')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
